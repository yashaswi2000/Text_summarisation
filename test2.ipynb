{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashaswi2000/Text_summarisation/blob/exp/test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFuL-RBgXqgU",
        "colab_type": "text"
      },
      "source": [
        "In this notebook, we will build an abstractive based text summarizer using deep learning from the scratch in python using keras\n",
        "\n",
        "I recommend you to go through the article over [here](https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/) to cover all the concepts which is required to build our own summarizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5dSoP8lGMZi",
        "colab_type": "text"
      },
      "source": [
        "#Understanding the Problem Statement\n",
        "\n",
        "Customer reviews can often be long and descriptive. Analyzing these reviews manually, as you can imagine, is really time-consuming. This is where the brilliance of Natural Language Processing can be applied to generate a summary for long reviews.\n",
        "\n",
        "We will be working on a really cool dataset. Our objective here is to generate a summary for the Amazon Fine Food reviews using the abstraction-based approach we learned about above. You can download the dataset from[ here ](https://www.kaggle.com/snap/amazon-fine-food-reviews)\n",
        "\n",
        "It’s time to fire up our Jupyter notebooks! Let’s dive into the implementation details right away.\n",
        "\n",
        "#Custom Attention Layer\n",
        "\n",
        "Keras does not officially support attention layer. So, we can either implement our own attention layer or use a third-party implementation. We will go with the latter option for this article. You can download the attention layer from [here](https://github.com/thushv89/attention_keras/blob/master/layers/attention.py) and copy it in a different file called attention.py.\n",
        "\n",
        "Let’s import it into our environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3_IRKnXzLIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Fi64aA0FFxcS",
        "colab_type": "code",
        "outputId": "689b10c7-4550-49cb-be28-991fc6b11f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "AttentionLayer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.AttentionLayer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUValOzcHtEK",
        "colab_type": "text"
      },
      "source": [
        "#Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "_Jpu8qLEFxcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_VTPwHmz1Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg0qiUVa0Tk4",
        "colab_type": "code",
        "outputId": "8b5d8ab5-c803-4c65-b259-1908f7118c50",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-694b7d4c-ab53-4f22-b9ee-bf95d5dd4217\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-694b7d4c-ab53-4f22-b9ee-bf95d5dd4217\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QBDUQCZ0Y8c",
        "colab_type": "code",
        "outputId": "51a39c4a-adda-4ec9-a629-64d0b220b77a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQec7P3p0d91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZDafTrd0hYE",
        "colab_type": "code",
        "outputId": "d79cc29a-5beb-44b3-e026-98010e85c101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!kaggle datasets download -d snap/amazon-fine-food-reviews"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "amazon-fine-food-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDu7a7Z60t42",
        "colab_type": "code",
        "outputId": "35cfab66-8897-48ce-9e3f-bfcb43549367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip amazon-fine-food-reviews.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  amazon-fine-food-reviews.zip\n",
            "replace Reviews.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVakjZ3oICgx",
        "colab_type": "text"
      },
      "source": [
        "#Read the dataset\n",
        "\n",
        "This dataset consists of reviews of fine foods from Amazon. The data spans a period of more than 10 years, including all ~500,000 reviews up to October 2012. These reviews include product and user information, ratings, plain text review, and summary. It also includes reviews from all other Amazon categories.\n",
        "\n",
        "We’ll take a sample of 100,000 reviews to reduce the training time of our model. Feel free to use the entire dataset for training your model if your machine has that kind of computational power."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wnK5o4Z1Fxcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(\"Reviews.csv\",nrows=100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scJZFk_1ANMl",
        "colab_type": "code",
        "outputId": "551181f4-3a10-4d8a-8e3b-5baf383ed3e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!kaggle datasets download -d pariza/bbc-news-summary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bbc-news-summary.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9bNgppsAXFt",
        "colab_type": "code",
        "outputId": "26207930-e041-4035-c3f3-c3ef1bb6e876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip bbc-news-summary.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  bbc-news-summary.zip\n",
            "replace BBC News Summary/News Articles/business/001.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naeaV0IKAvF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuZUTfUEAbBU",
        "colab_type": "code",
        "outputId": "228e742f-fb66-4d95-8d31-8080e723781b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        }
      },
      "source": [
        "data_path = \"./BBC News Summary\"\n",
        "folders = os.listdir(data_path)\n",
        "article_path = os.path.join(data_path,folders[0])\n",
        "summary_path = os.path.join(data_path,folders[1])\n",
        "categories = os.listdir(article_path)\n",
        "article_list = []\n",
        "summary_list = []\n",
        "for i in categories:\n",
        "  article_files = os.listdir(article_path + '/' + i)\n",
        "  summary_files = os.listdir(summary_path + '/' + i)\n",
        "  for j in range(len(article_files)):\n",
        "    file_path_1 = article_path + '/' + i + '/' + article_files[j]\n",
        "    file_path_2 = summary_path + '/' + i + '/' + summary_files[j]\n",
        "    #print(file_path_1)\n",
        "    try:\n",
        "        \n",
        "        f = open(file_path_1)\n",
        "        article_list.append(' '.join(f.read().splitlines()))\n",
        "        f = open(file_path_2)\n",
        "        summary_list.append(' '.join(f.read().splitlines()))\n",
        "        \n",
        "    except:\n",
        "        print(\"error\") \n",
        "d = {'article':article_list,'summary':summary_list}\n",
        "df = pd.DataFrame(d)\n",
        "data = df\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Women MPs reveal sexist taunts  Women MPs endure \"shocking\" levels of sexist abuse at the hands of their male counterparts, a new study shows.  Male MPs pretended to juggle imaginary breasts and j...</td>\n",
              "      <td>But she said there was a difference between the experiences of women before the 1997 intake and afterwards.Even after the great influx of women MPs at the 1997 general election, and greater number...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UK heading wrong way - Howard  Tony Blair has had the chance to tackle the problems facing Britain and has failed, Michael Howard has said.  \"Britain is heading in the wrong direction\", the Conser...</td>\n",
              "      <td>Tony Blair has had the chance to tackle the problems facing Britain and has failed, Michael Howard has said.The election will give Britain the chance to change.\"Mr Blair has failed to tackle these...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Blair stresses prosperity goals  Tony Blair says his party's next manifesto will be \"unremittingly New Labour\" and aimed at producing \"personal prosperity for all\".  The prime minister is trying t...</td>\n",
              "      <td>Mr Peston's book claimed that Mr Brown told Mr Blair: \"There is nothing you could ever say to me now that I could ever believe.\"In it he alleges that Mr Blair told Mr Brown in 2003 he would step d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UK 'needs true immigration data'  A former Home Office minister has called for an independent body to be set up to monitor UK immigration.  Barbara Roche said an organisation should monitor and pu...</td>\n",
              "      <td>She said this would counter \"so-called independent\" groups like Migration Watch, which she described as an anti-immigration body posing as independent.Migration Watch says it is not against all im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ministers lose slopping out case  The Scottish Executive has lost an appeal against an inmate's compensation for being forced to slop out in prison.  Armed robber Robert Napier, 25, won £2,450 aft...</td>\n",
              "      <td>Executive ministers raised an appeal arguing that the standard of proof to be applied in cases alleging a breach of the European Convention on Human Rights through degrading and inhumane treatment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2219</th>\n",
              "      <td>Sculthorpe wants Lions captaincy  Paul Sculthorpe has admitted he would love to succeed Andy Farrell as Great Britain skipper if the Wigan star does switch codes to rugby union.  Sculthorpe was vi...</td>\n",
              "      <td>Sculthorpe said the rugby league world would understand if Farrell did decide to move to rugby union.The 27-year-old, who captained St Helens to Challenge Cup success last year, said following in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>Butler strikes gold in Spain  Britain's Kathy Butler continued her impressive year with victory in Sunday's 25th Cross Internacional de Venta de Banos in Spain.  The Scot, who led GB to World Cros...</td>\n",
              "      <td>Gelete Burka then crowned a great day for Ethiopia by claiming victory in the women's race.Elsewhere, Abebe Dinkessa of Ethiopia won the Brussels IAAF cross-country race on Sunday, completing the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2221</th>\n",
              "      <td>McLeish ready for criticism  Rangers manager Alex McLeish accepts he is going to be criticised after their disastrous Uefa Cup exit at the hands of Auxerre at Ibrox on Wednesday.  McLeish told BBC...</td>\n",
              "      <td>McLeish admitted his team's defending was amateurish after watching them lose 2-0 to Guy Roux's French side.Rangers manager Alex McLeish accepts he is going to be criticised after their disastrous...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222</th>\n",
              "      <td>Venus stunned by Farina Elia  Venus Williams suffered a first-round defeat for the first time in four years at the Dubai Championships.  Sylvia Farina Elia, who had lost all nine of her previous m...</td>\n",
              "      <td>\"She (Kuznetsova) is a great player,\" she said.\"The first time I served again was Sunday and there wasn't a lot I could do out there.\"Blisters were a factor, but mostly my stomach wasn't that grea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2223</th>\n",
              "      <td>Robinson ready for difficult task  England coach Andy Robinson faces the first major test of his tenure as he tries to get back to winning ways after the Six Nations defeat by Wales.  Robinson is ...</td>\n",
              "      <td>England coach Andy Robinson faces the first major test of his tenure as he tries to get back to winning ways after the Six Nations defeat by Wales.The Bath fly-half-cum-centre is likely to start a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2224 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                      article                                                                                                                                                                                                  summary\n",
              "0     Women MPs reveal sexist taunts  Women MPs endure \"shocking\" levels of sexist abuse at the hands of their male counterparts, a new study shows.  Male MPs pretended to juggle imaginary breasts and j...  But she said there was a difference between the experiences of women before the 1997 intake and afterwards.Even after the great influx of women MPs at the 1997 general election, and greater number...\n",
              "1     UK heading wrong way - Howard  Tony Blair has had the chance to tackle the problems facing Britain and has failed, Michael Howard has said.  \"Britain is heading in the wrong direction\", the Conser...  Tony Blair has had the chance to tackle the problems facing Britain and has failed, Michael Howard has said.The election will give Britain the chance to change.\"Mr Blair has failed to tackle these...\n",
              "2     Blair stresses prosperity goals  Tony Blair says his party's next manifesto will be \"unremittingly New Labour\" and aimed at producing \"personal prosperity for all\".  The prime minister is trying t...  Mr Peston's book claimed that Mr Brown told Mr Blair: \"There is nothing you could ever say to me now that I could ever believe.\"In it he alleges that Mr Blair told Mr Brown in 2003 he would step d...\n",
              "3     UK 'needs true immigration data'  A former Home Office minister has called for an independent body to be set up to monitor UK immigration.  Barbara Roche said an organisation should monitor and pu...  She said this would counter \"so-called independent\" groups like Migration Watch, which she described as an anti-immigration body posing as independent.Migration Watch says it is not against all im...\n",
              "4     Ministers lose slopping out case  The Scottish Executive has lost an appeal against an inmate's compensation for being forced to slop out in prison.  Armed robber Robert Napier, 25, won £2,450 aft...  Executive ministers raised an appeal arguing that the standard of proof to be applied in cases alleging a breach of the European Convention on Human Rights through degrading and inhumane treatment...\n",
              "...                                                                                                                                                                                                       ...                                                                                                                                                                                                      ...\n",
              "2219  Sculthorpe wants Lions captaincy  Paul Sculthorpe has admitted he would love to succeed Andy Farrell as Great Britain skipper if the Wigan star does switch codes to rugby union.  Sculthorpe was vi...  Sculthorpe said the rugby league world would understand if Farrell did decide to move to rugby union.The 27-year-old, who captained St Helens to Challenge Cup success last year, said following in ...\n",
              "2220  Butler strikes gold in Spain  Britain's Kathy Butler continued her impressive year with victory in Sunday's 25th Cross Internacional de Venta de Banos in Spain.  The Scot, who led GB to World Cros...  Gelete Burka then crowned a great day for Ethiopia by claiming victory in the women's race.Elsewhere, Abebe Dinkessa of Ethiopia won the Brussels IAAF cross-country race on Sunday, completing the ...\n",
              "2221  McLeish ready for criticism  Rangers manager Alex McLeish accepts he is going to be criticised after their disastrous Uefa Cup exit at the hands of Auxerre at Ibrox on Wednesday.  McLeish told BBC...  McLeish admitted his team's defending was amateurish after watching them lose 2-0 to Guy Roux's French side.Rangers manager Alex McLeish accepts he is going to be criticised after their disastrous...\n",
              "2222  Venus stunned by Farina Elia  Venus Williams suffered a first-round defeat for the first time in four years at the Dubai Championships.  Sylvia Farina Elia, who had lost all nine of her previous m...  \"She (Kuznetsova) is a great player,\" she said.\"The first time I served again was Sunday and there wasn't a lot I could do out there.\"Blisters were a factor, but mostly my stomach wasn't that grea...\n",
              "2223  Robinson ready for difficult task  England coach Andy Robinson faces the first major test of his tenure as he tries to get back to winning ways after the Six Nations defeat by Wales.  Robinson is ...  England coach Andy Robinson faces the first major test of his tenure as he tries to get back to winning ways after the Six Nations defeat by Wales.The Bath fly-half-cum-centre is likely to start a...\n",
              "\n",
              "[2224 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGNQKvCaISIn",
        "colab_type": "text"
      },
      "source": [
        "# Drop Duplicates and NA values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Cjul88oOFxcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop_duplicates(subset=['article'],inplace=True)#dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)#dropping na"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi0xD6BkIWAm",
        "colab_type": "text"
      },
      "source": [
        "# Information about dataset\n",
        "\n",
        "Let us look at datatypes and shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "__fy-JxTFxc9",
        "colab_type": "code",
        "outputId": "fbfe51ec-5cf3-475b-e0c0-5239addb5749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2126 entries, 0 to 2223\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   article  2126 non-null   object\n",
            " 1   summary  2126 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 49.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0xLYACiFxdJ",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing\n",
        "\n",
        "Performing basic preprocessing steps is very important before we get to the model building part. Using messy and uncleaned text data is a potentially disastrous move. So in this step, we will drop all the unwanted symbols, characters, etc. from the text that do not affect the objective of our problem.\n",
        "\n",
        "Here is the dictionary that we will use for expanding the contractions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0s6IY-x2FxdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JFRXFHmI7Mj",
        "colab_type": "text"
      },
      "source": [
        "We will perform the below preprocessing tasks for our data:\n",
        "\n",
        "1.Convert everything to lowercase\n",
        "\n",
        "2.Remove HTML tags\n",
        "\n",
        "3.Contraction mapping\n",
        "\n",
        "4.Remove (‘s)\n",
        "\n",
        "5.Remove any text inside the parenthesis ( )\n",
        "\n",
        "6.Eliminate punctuations and special characters\n",
        "\n",
        "7.Remove stopwords\n",
        "\n",
        "8.Remove short words\n",
        "\n",
        "Let’s define the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhq0X88D1HY3",
        "colab_type": "code",
        "outputId": "949b0d96-470d-4013-9225-4b0b2aa089e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XZr-u3OEFxdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A2QAeCHWFxdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#call the function\n",
        "cleaned_text = []\n",
        "for t in data['article']:\n",
        "    cleaned_text.append(text_cleaner(t,0)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snRZY8wjLao2",
        "colab_type": "text"
      },
      "source": [
        "Let us look at the first five preprocessed reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NCAIkhWbFxdh",
        "colab_type": "code",
        "outputId": "d0580541-d5fc-4b9a-d1bc-0ccc505292b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "cleaned_text[:5]  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['women mps reveal sexist taunts women mps endure shocking levels sexist abuse hands male counterparts new study shows male mps pretended juggle imaginary breasts jeered melons women made commons speeches researchers birkbeck college told labour yvette cooper said found hard persuade commons officials minister secretary mps gave answers hours taped interviews study whose secretary minister research team professor joni lovenduski set look achievements experiences women westminster emerged complaints mps parties sexist barracking chamber sexist insults patronising assumptions abilities barbara follet one called blair babes elected told researchers remember conservatives whenever labour woman got speak would take breasts imaginary breasts hands wiggle say melons spoke former liberal democrat mp jackie ballard recalled stream remarks leading mp topics women legs sexual persuasion ex tory education secretary gillian shepherd remembered one male colleagues called women betty said look know name betty said ah call betty harriet harman told researchers sheer hostility prompted advancement cabinet well succeeded woman another current member cabinet says told oh fast rise sleeping even great influx women mps general election greater numbers women cabinet female mps often say feel stuck edge male world liberal democrat sarah teather recent female mp elected told researchers lots people say like old boys club always said feels like teenage public school know public school full teenagers prof joni lovenduski conducted study help margaret moran mp team journalists said shocked findings expected bit nothing like extent expected find couple shocking episodes said difference experiences women intake afterwards mainly women present parliament prepared put sexist attitudes came across prof lovenduski said added women including women came received extraordinary treatment convinced number women changed back things would change back think shocking general public things go house commons interviews placed british library historical record',\n",
              " 'uk heading wrong way howard tony blair chance tackle problems facing britain failed michael howard said britain heading wrong direction conservative leader said new year message mr blair government bossy interfering government takes decisions made individuals added labour campaign spokesman fraser kemp responded britain working let tories wreck mr howard also paid tribute nation character generous response asian quake disaster catastrophe overshadowing hopes future usually positive time year mr howard said watched scenes destruction sense disbelief scale speed ferocity happened boxing day difficult grasp yet britain response shone light nation character last week shown warm caring heart britain beats strong ever went reflect values britons hold dear looking ahead coming general election pledged turn beliefs reality set choices says facing britain much tax people want pay give taxpayers value money clean hospitals good disciplined schools want trusted get grip disorder streets chaos immigration system mr blair failed tackle problems claimed saying wrong solution result big government higher taxes eroding incentives undermining enterprise denying people choice worst government wasted people money failed tackle problems families face today tories said cut crime improve public services without asking people pay taxes progress without losing makes britain great tolerance respect rule law ability everyone fulfil potential simply need change direction election give britain chance change record mr blair defend coming months said urging voters hold account labour spokesman mr kemp said would appropriate message come april january let us never forget michael howard government britain suffered mass unemployment interest rates record home repossessions introduction poll tax labour britain working rather alluding false promises michael howard starting apology british people misery government member inflicted upon country',\n",
              " 'blair stresses prosperity goals tony blair says party next manifesto unremittingly new labour aimed producing personal prosperity prime minister trying draw line speculation state relationship gordon brown speech chatham kent saying prosperity means individual wealth ensuring radically improved public services also claiming labour ideologically united ever mr brown currently touring africa week facing questions reports splits downing street election widely predicted may angry labour mps week warned mr blair mr brown dangers disunity mr blair trying put focus substance labour platform third term government labour made low inflation unemployment mortgage rates centrepiece new poster campaign week thursday mr blair saying want talk central purpose ofnew labour increase personal prosperity well justfor prosperity mean income wealth individuals theirfamilies opportunity security available radicallyimproved public services reformed welfare state tories trying capitalise apparent feud top government wednesday unveiled poster pictured prime minister mr brown words fight crime fighting michael howard frontbencher john redwood thursday launched new plans abolish hundreds quangos say government spending much lower taxes needed make britain competitive liberal democrats also claimed infighting obstructing good government latest speculation relations new labour two powerful figures came publication new book brown britain robert preston alleges mr blair told mr brown would step prime minister coming general election book claims premier went back pledge support cabinet allies suspicion mr brown manoeuvring mr peston book claimed mr brown told mr blair nothing could ever say could ever believe wednesday mr blair directly denied mr brown made quote left africa tuesday chancellor told reporters course trust prime minister',\n",
              " 'uk needs true immigration data former home office minister called independent body set monitor uk immigration barbara roche said organisation monitor publish figures independent government said would counter called independent groups like migration watch described anti immigration body posing independent migration watch says immigration government already publishes accurate figures sir andrew green chairman organisation says need independent body office national statistics data accurate says opposes large scale immigration grounds overcrowding culture said example next years one household three due immigration already overcrowded india four times overcrowded france ms roche labour mp hornsey wood green believes legal migration something welcome said proposals mean would called independent experts like migration watch come debate anti immigration point view went would like see body actually looked figures published independent government think would go long way allaying fears sometimes whipped debate',\n",
              " 'ministers lose slopping case scottish executive lost appeal inmate compensation forced slop prison armed robber robert napier claimed suffered outbreak skin complaint eczema slopping barlinnie prison napier said practice prisoners use buckets cells toilets breached human rights thursday court session threw move executive apply rigorous standard proof executive faces similar claims damages prisoners former inmates actions already raised court session sheriff courts scotland executive spokesman said study judgement detail much changed address issues raised napier case example slopping ended barlinnie work prisons accelerated today judgement affect outcome cases napier remand prisoner time raised legal challenge european convention human rights sought awarded compensation last april winning case executive ministers raised appeal arguing standard proof applied cases alleging breach european convention human rights degrading inhumane treatment beyond reasonable doubt standard normally applied criminal trials scotland however civil litigation settled test balance probabilities judge lord cullen sitting lord osborne lord hamilton ruled alleged human rights breaches involving degrading treatment dealt normal civil standard napier lawyer tony kelly believes action soon followed others mr kelly said hundreds people still undergoing slopping overcrowding poor regime people certainly heartened today judgement scottish national party justice minister kenny macaskill said slopping case fiasco start finish said ministers fully aware state scotland jails funds available chose ignore problem ruling suspect faced even claims doubt payouts short term executive saving resulted long term public cost']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GsRXocxoFxd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#call the function\n",
        "cleaned_summary = []\n",
        "for t in data['summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZeD0gs6Lnb-",
        "colab_type": "text"
      },
      "source": [
        "Let us look at the first 10 preprocessed summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jQJdZcAzFxee",
        "colab_type": "code",
        "outputId": "ebbb9be8-4a17-490f-f2b0-8a2469e8ee3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "cleaned_summary[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['but she said there was difference between the experiences of women before the intake and afterwards even after the great influx of women mps at the general election and greater numbers of women in the cabinet female mps often say they feel stuck on the edge of male world this was mainly because there were more women present in parliament who were not prepared to put up with the sexist attitudes they came across prof lovenduski said male mps pretended to juggle imaginary breasts and jeered melons as women made commons speeches researchers from birkbeck college were told prof joni lovenduski who conducted the study with the help of margaret moran mp and team of journalists said she was shocked at the findings but she added some women including the women who came in received extraordinary treatment and am not convinced that if the number of women changed back to what it was before that things would not change back labour yvette cooper said she found it hard to persuade commons officials she was minister and not secretary women mps endure shocking levels of sexist abuse at the hands of their male counterparts new study shows and ex tory education secretary gillian shepherd remembered how one of her male colleagues called all women betty barbara follet one of the so called blair babes elected in told researchers remember some conservatives whenever labour woman got up to speak they would take their breasts imaginary breasts in their hands and wiggle them and say melons as we spoke',\n",
              " 'tony blair has had the chance to tackle the problems facing britain and has failed michael howard has said the election will give britain the chance to change mr blair has failed to tackle these problems he claimed saying he has the wrong solution to them let us never forget that when michael howard was in government britain suffered mass unemployment interest rates record home repossessions and the introduction of the poll tax britain is heading in the wrong direction the conservative leader said in his new year message with labour britain is working the catastrophe was overshadowing the hopes for the future at this usually positive time of the year mr howard said this is the record mr blair will have to defend in the coming months he said urging voters to hold him to account worst of all it is government that has wasted people money and failed to tackle the problems families face today the last week has shown that the warm caring heart of britain beats as strong as ever but labour spokesman mr kemp said it would be more appropriate for this message to come out on april not january',\n",
              " 'mr peston book claimed that mr brown told mr blair there is nothing you could ever say to me now that could ever believe in it he alleges that mr blair told mr brown in he would step down as prime minister before the coming general election with the election widely predicted for may angry labour mps this week warned mr blair and mr brown about the dangers of disunity on wednesday mr blair directly denied mr brown made that quote and before he left for africa on tuesday the chancellor told reporters of course trust the prime minister and on thursday mr blair is saying want to talk about the central purpose ofnew labour which is to increase personal prosperity and well being not justfor few but for all now mr blair is trying to put the focus on the substance of labour platform for third term in government on wednesday they unveiled poster which pictured the prime minister and mr brown under the words how can they fight crime when they are fighting each other tony blair says his party next manifesto will be unremittingly new labour and aimed at producing personal prosperity for all',\n",
              " 'she said this would counter so called independent groups like migration watch which she described as an anti immigration body posing as independent migration watch says it is not against all immigration and the government already publishes accurate figures she said her proposals mean we would not have so called independent experts like migration watch who come into this debate from an anti immigration point of view she went on what would like to see is there being body which actually looked at the figures published them and was independent of government barbara roche said an organisation should monitor and publish figures and be independent of government',\n",
              " 'executive ministers raised an appeal arguing that the standard of proof to be applied in cases alleging breach of the european convention on human rights through degrading and inhumane treatment should be beyond reasonable doubt an executive spokesman said we will study this judgement in detail the scottish executive has lost an appeal against an inmate compensation for being forced to slop out in prison much has changed to address the issues raised in the napier case for example slopping out has ended at barlinnie and work in other prisons is being accelerated napier said that the practice where prisoners use buckets in their cells as toilets breached his human rights on thursday the court of session threw out move by the executive to apply more rigorous standard of proof napier remand prisoner at the time raised legal challenge in under the european convention on human rights in which he sought the executive faces more than similar claims for damages from prisoners and former inmates scottish national party justice minister kenny macaskill said that the slopping out case had been fiasco from start to finish',\n",
              " 'lord goldsmith said the answer represented his genuinely held independent view the war was legal former foreign secretary robin cook said lord goldsmith admission that his parliamentary answer was not summary of his legal opinion suggested parliament may have been misled the attorney general may never have presented his answer as summary but others certainly did he said last week lord goldsmith said in statement was fully involved throughout the drafting process and personally finalised and of course approved the answer in the house of lords the attorney general faced call by former tory lord chancellor lord mackay to now publish the full text of the advice the suggestion was rejected tony blair has dismissed questions about the attorney general advice and said his parliamentary statement had been fair summary of his opinion the answer did not purport to be summary of my confidential legal advice to government as have always made clear set out in the answer my own genuinely held independent view that military action was lawful under the existing security council resolutions he said another peer meanwhile lord skidelsky said not to publish the full legal opinion would strengthen the suspicion that the the original text was doctored for public consumption in exactly the same way as the notorious intelligence dossier on weapons of mass destruction short statement about lord goldsmith position presented in written parliamentary answer on march just before crucial commons vote on the military action did not suggest this he said the answer had been prepared in his office with the involvement of solicitor general harriet harman two of his own officials three foreign office officials qc christopher greenwood and the then lord chancellor lord irvine of lairg',\n",
              " 'bbc political editor andrew marr said that mr brown article was warning shot to mr blair not to try and cut him out of the manifesto writing process mr blair argued that under new labour the country had changed for the better and that was in part because of mr brown management of the economy mr blair said decision had yet to be taken over how the election would be run but the chancellor role would be central the prime minister was asked about mr brown article and about his election role when he appeared on bbc radio today programme the premier insisted mr brown will have key role in labour campaign and praised his handling of the economy mr blair said he was taking nothing for granted ahead of the vote warning that the tory strategy was to win power via the back door by hinting they were aiming to cut labour majority instead of hoping for an outright win',\n",
              " 'tony blair has said he does not want higher tax rates for top earners but on wednesday said other tax promises would be left to labour manifesto he attacked tory plans to process asylum claims abroad but mr howard said labour had proposed the idea too it was no good mr blair claiming tax pledges were being left to the manifesto as he had given one to mps on tuesday about the top rate of income tax argued mr howard prime minister questions also saw mr blair predict that new plans would probably cut net immigration mr howard read from letter about the government own plans at the european council of ministers for processing asylum seekers outside the eu pointing to national insurance he added everyone knows tax will go up under labour is not it now clear which tax it would be mr blair said abuses would be weeded out and chain migration where families automatically get the right to settle with immigrant workers would end mr howard pointed to the institute for fiscal studies predictions that labour will need to increase taxes to cover an bn gap in its spending plans',\n",
              " 'home secretary charles clarke has been quoted as telling labour members he wants more migrants to come to the uk the latest pre election spats come after mr blair told labour members the tories offered hard right agenda which would take britain backwards but mr clarke accused him of trying to score cheap political points by muddling immigration with asylum mr blair was asked last wednesday if the government new immigration plans including point system for economic migrants would reduce net migration mr clarke said he had made clear the uk would welcome genuine economic migrants for key jobs on strict points based system earlier dr fox accused mr blair and other cabinet ministers of telling lies about tory policies and then attacking the lies london evening standard quoted mr clarke telling labour activists at question and answer session in gateshead that he wanted britain to offer refuge for those fleeing tyranny mr clarke dismissed the latest tory attack labour has already broken its pre election promise on immigration before the ink has dried on its new pledge card the tories have claimed on monday dr fox told reporters the prime minister has broken his word so many times in the past but now his promises do not even last week',\n",
              " 'the labour party will hold its autumn conference in manchester and not blackpool it has been confirmed for years the main political parties have rotated between blackpool bournemouth and brighton in the party said it would not return to blackpool but did so in and the news the much larger annual conference is not to gather in blackpool will be seen as blow in the coastal resort colin asplin blackpool hotel association said we have tried very hard to make sure they come back to blackpool it will be the first time since that the party has chosen manchester to host the annual event']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "L1zLpnqsFxey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT_D2cLiLy77",
        "colab_type": "text"
      },
      "source": [
        "#Drop empty rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sYK390unFxfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm8Fk2TCL7Sp",
        "colab_type": "text"
      },
      "source": [
        "#Understanding the distribution of the sequences\n",
        "\n",
        "Here, we will analyze the length of the reviews and the summary to get an overall idea about the distribution of length of the text. This will help us fix the maximum length of the sequence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MdF76AHHFxgw",
        "colab_type": "code",
        "outputId": "bf2c324c-9aa4-4138-d47a-4f2f4fe5adf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwdSGIhGMEbz",
        "colab_type": "text"
      },
      "source": [
        "Interesting. We can fix the maximum length of the summary to 8 since that seems to be the majority summary length.\n",
        "\n",
        "Let us understand the proportion of the length of summaries below 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7JRjwdIOFxg3",
        "colab_type": "code",
        "outputId": "c6f5c671-4f7e-4f7b-9768-3636b35c133e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cnt=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=400):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_summary']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9840075258701787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYNwCl0zH3sB",
        "colab_type": "code",
        "outputId": "6391d6eb-02f7-4282-e9ec-7769cb5a628f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cnt=0\n",
        "for i in data['cleaned_text']:\n",
        "    if(len(i.split())<=350):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_text']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.90310442144873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYB4Ga9KMjEu",
        "colab_type": "text"
      },
      "source": [
        "We observe that 94% of the summaries have length below 8. So, we can fix maximum length of summary to 8.\n",
        "\n",
        "Let us fix the maximum length of review to 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZKD5VOWqFxhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_text_len=300\n",
        "max_summary_len=300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6d48E-8M4VO",
        "colab_type": "text"
      },
      "source": [
        "Let us select the reviews and summaries whose length falls below or equal to **max_text_len** and **max_summary_len**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yY0tEJP0FxhI",
        "colab_type": "code",
        "outputId": "1b0d24be-5061-4c04-8cdb-196746f5d500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        }
      },
      "source": [
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>women mps reveal sexist taunts women mps endure shocking levels sexist abuse hands male counterparts new study shows male mps pretended juggle imaginary breasts jeered melons women made commons sp...</td>\n",
              "      <td>but she said there was difference between the experiences of women before the intake and afterwards even after the great influx of women mps at the general election and greater numbers of women in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>uk heading wrong way howard tony blair chance tackle problems facing britain failed michael howard said britain heading wrong direction conservative leader said new year message mr blair governmen...</td>\n",
              "      <td>tony blair has had the chance to tackle the problems facing britain and has failed michael howard has said the election will give britain the chance to change mr blair has failed to tackle these p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blair stresses prosperity goals tony blair says party next manifesto unremittingly new labour aimed producing personal prosperity prime minister trying draw line speculation state relationship gor...</td>\n",
              "      <td>mr peston book claimed that mr brown told mr blair there is nothing you could ever say to me now that could ever believe in it he alleges that mr blair told mr brown in he would step down as prime...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>uk needs true immigration data former home office minister called independent body set monitor uk immigration barbara roche said organisation monitor publish figures independent government said wo...</td>\n",
              "      <td>she said this would counter so called independent groups like migration watch which she described as an anti immigration body posing as independent migration watch says it is not against all immig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ministers lose slopping case scottish executive lost appeal inmate compensation forced slop prison armed robber robert napier claimed suffered outbreak skin complaint eczema slopping barlinnie pri...</td>\n",
              "      <td>executive ministers raised an appeal arguing that the standard of proof to be applied in cases alleging breach of the european convention on human rights through degrading and inhumane treatment s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1766</th>\n",
              "      <td>sculthorpe wants lions captaincy paul sculthorpe admitted would love succeed andy farrell great britain skipper wigan star switch codes rugby union sculthorpe vice captain tri nations took st hele...</td>\n",
              "      <td>sculthorpe said the rugby league world would understand if farrell did decide to move to rugby union the year old who captained st helens to challenge cup success last year said following in the f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1767</th>\n",
              "      <td>butler strikes gold spain britain kathy butler continued impressive year victory sunday th cross internacional de venta de banos spain scot led gb world cross country bronze earlier year moved awa...</td>\n",
              "      <td>gelete burka then crowned great day for ethiopia by claiming victory in the women race elsewhere abebe dinkessa of ethiopia won the brussels iaaf cross country race on sunday completing the course...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1768</th>\n",
              "      <td>mcleish ready criticism rangers manager alex mcleish accepts going criticised disastrous uefa cup exit hands auxerre ibrox wednesday mcleish told bbc radio five live pole position get next stage b...</td>\n",
              "      <td>mcleish admitted his team defending was amateurish after watching them lose to guy roux french side rangers manager alex mcleish accepts he is going to be criticised after their disastrous uefa cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1769</th>\n",
              "      <td>venus stunned farina elia venus williams suffered first round defeat first time four years dubai championships sylvia farina elia lost nine previous meetings american fifth seed former wimbledon c...</td>\n",
              "      <td>she is great player she said the first time served again was sunday and there was not lot could do out there blisters were factor but mostly my stomach was not that great she said mirza the first ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1770</th>\n",
              "      <td>robinson ready difficult task england coach andy robinson faces first major test tenure tries get back winning ways six nations defeat wales robinson likely make changes back row centre loss conte...</td>\n",
              "      <td>england coach andy robinson faces the first major test of his tenure as he tries to get back to winning ways after the six nations defeat by wales the bath fly half cum centre is likely to start a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1771 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                         text                                                                                                                                                                                                  summary\n",
              "0     women mps reveal sexist taunts women mps endure shocking levels sexist abuse hands male counterparts new study shows male mps pretended juggle imaginary breasts jeered melons women made commons sp...  but she said there was difference between the experiences of women before the intake and afterwards even after the great influx of women mps at the general election and greater numbers of women in...\n",
              "1     uk heading wrong way howard tony blair chance tackle problems facing britain failed michael howard said britain heading wrong direction conservative leader said new year message mr blair governmen...  tony blair has had the chance to tackle the problems facing britain and has failed michael howard has said the election will give britain the chance to change mr blair has failed to tackle these p...\n",
              "2     blair stresses prosperity goals tony blair says party next manifesto unremittingly new labour aimed producing personal prosperity prime minister trying draw line speculation state relationship gor...  mr peston book claimed that mr brown told mr blair there is nothing you could ever say to me now that could ever believe in it he alleges that mr blair told mr brown in he would step down as prime...\n",
              "3     uk needs true immigration data former home office minister called independent body set monitor uk immigration barbara roche said organisation monitor publish figures independent government said wo...  she said this would counter so called independent groups like migration watch which she described as an anti immigration body posing as independent migration watch says it is not against all immig...\n",
              "4     ministers lose slopping case scottish executive lost appeal inmate compensation forced slop prison armed robber robert napier claimed suffered outbreak skin complaint eczema slopping barlinnie pri...  executive ministers raised an appeal arguing that the standard of proof to be applied in cases alleging breach of the european convention on human rights through degrading and inhumane treatment s...\n",
              "...                                                                                                                                                                                                       ...                                                                                                                                                                                                      ...\n",
              "1766  sculthorpe wants lions captaincy paul sculthorpe admitted would love succeed andy farrell great britain skipper wigan star switch codes rugby union sculthorpe vice captain tri nations took st hele...  sculthorpe said the rugby league world would understand if farrell did decide to move to rugby union the year old who captained st helens to challenge cup success last year said following in the f...\n",
              "1767  butler strikes gold spain britain kathy butler continued impressive year victory sunday th cross internacional de venta de banos spain scot led gb world cross country bronze earlier year moved awa...  gelete burka then crowned great day for ethiopia by claiming victory in the women race elsewhere abebe dinkessa of ethiopia won the brussels iaaf cross country race on sunday completing the course...\n",
              "1768  mcleish ready criticism rangers manager alex mcleish accepts going criticised disastrous uefa cup exit hands auxerre ibrox wednesday mcleish told bbc radio five live pole position get next stage b...  mcleish admitted his team defending was amateurish after watching them lose to guy roux french side rangers manager alex mcleish accepts he is going to be criticised after their disastrous uefa cu...\n",
              "1769  venus stunned farina elia venus williams suffered first round defeat first time four years dubai championships sylvia farina elia lost nine previous meetings american fifth seed former wimbledon c...  she is great player she said the first time served again was sunday and there was not lot could do out there blisters were factor but mostly my stomach was not that great she said mirza the first ...\n",
              "1770  robinson ready difficult task england coach andy robinson faces first major test tenure tries get back winning ways six nations defeat wales robinson likely make changes back row centre loss conte...  england coach andy robinson faces the first major test of his tenure as he tries to get back to winning ways after the six nations defeat by wales the bath fly half cum centre is likely to start a...\n",
              "\n",
              "[1771 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR1uh8xSNUma",
        "colab_type": "text"
      },
      "source": [
        "Remember to add the **START** and **END** special tokens at the beginning and end of the summary. Here, I have chosen **sostok** and **eostok** as START and END tokens\n",
        "\n",
        "**Note:** Be sure that the chosen special tokens never appear in the summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EwLUH78CFxhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GlcX4RFOh13",
        "colab_type": "text"
      },
      "source": [
        "We are getting closer to the model building part. Before that, we need to split our dataset into a training and validation set. We’ll use 90% of the dataset as the training data and evaluate the performance on the remaining 10% (holdout set):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RakakKHcFxhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.2,random_state=0,shuffle=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq1mqyOHOtIl",
        "colab_type": "text"
      },
      "source": [
        "#Preparing the Tokenizer\n",
        "\n",
        "A tokenizer builds the vocabulary and converts a word sequence to an integer sequence. Go ahead and build tokenizers for text and summary:\n",
        "\n",
        "#Text Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oRHTgX6hFxhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzvLwYL_PDcx",
        "colab_type": "text"
      },
      "source": [
        "#Rarewords and its Coverage\n",
        "\n",
        "Let us look at the proportion rare words and its total coverage in the entire text\n",
        "\n",
        "Here, I am defining the threshold to be 4 which means word whose count is below 4 is considered as a rare word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y8KronV2Fxhx",
        "colab_type": "code",
        "outputId": "40052e81-2230-4f64-da6a-6db7a47e342a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 59.64701356160431\n",
            "Total Coverage of rare words: 7.485300053022689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So-J-5kzQIeO",
        "colab_type": "text"
      },
      "source": [
        "**Remember**:\n",
        "\n",
        "\n",
        "* **tot_cnt** gives the size of vocabulary (which means every unique words in the text)\n",
        " \n",
        "*   **cnt** gives me the no. of rare words whose count falls below threshold\n",
        "\n",
        "*  **tot_cnt - cnt** gives me the top most common words \n",
        "\n",
        "Let us define the tokenizer with top most common words for reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J2giEsF3Fxh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DCbGMsm4FxiA",
        "colab_type": "code",
        "outputId": "decf04d2-7211-4ccf-8140-83ddb0aadca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_voc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQfKP3sqRxi9",
        "colab_type": "text"
      },
      "source": [
        "#Summary Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eRHqyBkBFxiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KInA6O6ZSkJz",
        "colab_type": "text"
      },
      "source": [
        "#Rarewords and its Coverage\n",
        "\n",
        "Let us look at the proportion rare words and its total coverage in the entire summary\n",
        "\n",
        "Here, I am defining the threshold to be 6 which means word whose count is below 6 is considered as a rare word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yzE5OiRLFxiM",
        "colab_type": "code",
        "outputId": "94afb739-fc13-44f0-fc3f-08a1efe89efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 73.89479574706212\n",
            "Total Coverage of rare words: 10.470579074415346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PBhzKuRSw_9",
        "colab_type": "text"
      },
      "source": [
        "Let us define the tokenizer with top most common words for summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-fswLvIgFxiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqwDUT5oTFmn",
        "colab_type": "text"
      },
      "source": [
        "Let us check whether word count of start token is equal to length of the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pR8IX9FRFxiY",
        "colab_type": "code",
        "outputId": "7539725d-6402-4367-a5f1-d820c5cb89f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_tokenizer.word_counts['sostok'],len(y_tr)   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1416, 1416)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVFhFVguTTtw",
        "colab_type": "text"
      },
      "source": [
        "Here, I am deleting the rows that contain only **START** and **END** tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kZ-vW82sFxih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cx5NISuMFxik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_eoeIWt3Jfr",
        "colab_type": "code",
        "outputId": "0b0fb347-aa17-429d-c403-4d6d388cea90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "pip install keras==2.2.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOtlDcthFxip",
        "colab_type": "text"
      },
      "source": [
        "# Model building\n",
        "\n",
        "We are finally at the model building part. But before we do that, we need to familiarize ourselves with a few terms which are required prior to building the model.\n",
        "\n",
        "**Return Sequences = True**: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
        "\n",
        "**Return State = True**: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
        "\n",
        "**Initial State**: This is used to initialize the internal states of the LSTM for the first timestep\n",
        "\n",
        "**Stacked LSTM**: Stacked LSTM has multiple layers of LSTM stacked on top of each other. \n",
        "This leads to a better representation of the sequence. I encourage you to experiment with the multiple layers of the LSTM stacked on top of each other (it’s a great way to learn this)\n",
        "\n",
        "Here, we are building a 3 stacked LSTM for the encoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zXef38nBFxir",
        "colab_type": "code",
        "outputId": "bec53162-3809-4437-d343-3ba936068748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "from keras import backend as K \n",
        "#K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           [(None, 300)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, 300, 100)     839200      input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_20 (LSTM)                  [(None, 300, 300), ( 481200      embedding_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_24 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_21 (LSTM)                  [(None, 300, 300), ( 721200      lstm_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, None, 100)    373300      input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_22 (LSTM)                  [(None, 300, 300), ( 721200      lstm_21[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_23 (LSTM)                  [(None, None, 300),  481200      embedding_11[0][0]               \n",
            "                                                                 lstm_22[0][1]                    \n",
            "                                                                 lstm_22[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_22[0][0]                    \n",
            "                                                                 lstm_23[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_23[0][0]                    \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, None, 3733)   2243533     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 6,041,133\n",
            "Trainable params: 6,041,133\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZVlfRuMUcoP",
        "colab_type": "text"
      },
      "source": [
        "I am using sparse categorical cross-entropy as the loss function since it converts the integer sequence to a one-hot vector on the fly. This overcomes any memory issues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lwfi1Fm8Fxiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0ykDbxfUhyw",
        "colab_type": "text"
      },
      "source": [
        "Remember the concept of early stopping? It is used to stop training the neural network at the right time by monitoring a user-specified metric. Here, I am monitoring the validation loss (val_loss). Our model will stop training once the validation loss increases:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-A3J92MUljB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw6CVECaUq5b",
        "colab_type": "text"
      },
      "source": [
        "We’ll train the model on a batch size of 128 and validate it on the holdout set (which is 10% of our dataset):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ETnPzA4OFxi3",
        "colab_type": "code",
        "outputId": "e97d3439-2478-4845-e833-ad22082fcd75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=50, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 1/29 [>.............................] - ETA: 0s - loss: 8.2303"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-38bff3b3bc31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ezKYOp2UxG5",
        "colab_type": "text"
      },
      "source": [
        "#Understanding the Diagnostic plot\n",
        "\n",
        "Now, we will plot a few diagnostic plots to understand the behavior of the model over time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tDTNLAURFxjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSyx-HvpUz2o",
        "colab_type": "text"
      },
      "source": [
        "From the plot, we can infer that validation loss has increased after epoch 17 for 2 successive epochs. Hence, training is stopped at epoch 19.\n",
        "\n",
        "Next, let’s build the dictionary to convert the index to word for target and source vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sBX0zZnOFxjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM_nU_VvFxjq",
        "colab_type": "text"
      },
      "source": [
        "# Inference\n",
        "\n",
        "Set up the inference for the encoder and decoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9QkrNV-4Fxjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOiyk4ToWe74",
        "colab_type": "text"
      },
      "source": [
        "We are defining a function below which is the implementation of the inference process (which we covered [here](https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6f6TTFnBFxj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GuDf4TPWt6_",
        "colab_type": "text"
      },
      "source": [
        "Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aAUntznIFxj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gM4ALyfWwA9",
        "colab_type": "text"
      },
      "source": [
        "Here are a few summaries generated by the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BUtQmQTmFxkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTkaYNjHW4lC",
        "colab_type": "text"
      },
      "source": [
        "This is really cool stuff. Even though the actual summary and the summary generated by our model do not match in terms of words, both of them are conveying the same meaning. Our model is able to generate a legible summary based on the context present in the text.\n",
        "\n",
        "This is how we can perform text summarization using deep learning concepts in Python.\n",
        "\n",
        "#How can we Improve the Model’s Performance Even Further?\n",
        "\n",
        "Your learning doesn’t stop here! There’s a lot more you can do to play around and experiment with the model:\n",
        "\n",
        "I recommend you to **increase the training dataset** size and build the model. The generalization capability of a deep learning model enhances with an increase in the training dataset size\n",
        "\n",
        "Try implementing **Bi-Directional LSTM** which is capable of capturing the context from both the directions and results in a better context vector\n",
        "\n",
        "Use the **beam search strategy** for decoding the test sequence instead of using the greedy approach (argmax)\n",
        "\n",
        "Evaluate the performance of your model based on the **BLEU score**\n",
        "\n",
        "Implement **pointer-generator networks** and **coverage mechanisms**\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_qIecuvY5GT",
        "colab_type": "text"
      },
      "source": [
        "#End Notes\n",
        "\n",
        "If you have any feedback on this article or any doubts/queries, kindly share them in the comments section over [here](https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/) and I will get back to you. And make sure you experiment with the model we built here and share your results with me!"
      ]
    }
  ]
}